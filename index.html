<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>MVP-LAM | Cross-Viewpoint Reconstruction</title>
    <meta
      name="description"
      content="MVP-LAM learns action-centric discrete latent actions from time-synchronized multi-view videos via cross-viewpoint reconstruction."
    />

    <meta property="og:title" content="MVP-LAM" />
    <meta
      property="og:description"
      content="Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction"
    />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://latentactionpretraining.github.io/" />

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />

    <style>
      :root {
        --bg: #0b0c10;
        --text: #e9eef5;
        --muted: #aab4c3;
        --line: rgba(255, 255, 255, 0.10);
        --accent: #7aa2ff;
        --accent2: #a6ffcb;
        --shadow: 0 10px 30px rgba(0, 0, 0, 0.40);
      }

      * { box-sizing: border-box; }
      html, body { height: 100%; }
      body {
        margin: 0;
        font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
        background:
          radial-gradient(1200px 700px at 20% 0%, rgba(122, 162, 255, 0.22), transparent 60%),
          radial-gradient(900px 600px at 85% 15%, rgba(166, 255, 203, 0.12), transparent 55%),
          var(--bg);
        color: var(--text);
        line-height: 1.55;
      }

      a { color: inherit; text-decoration: none; }
      a:hover { text-decoration: underline; }

      .wrap {
        width: min(980px, calc(100% - 40px));
        margin: 0 auto;
        padding: 26px 0 64px;
      }

      header {
        display: grid;
        gap: 16px;
        padding: 22px 0 10px;
      }

      .topbar {
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 12px;
        flex-wrap: wrap;
      }

      .badge {
        display: inline-flex;
        align-items: center;
        gap: 10px;
        padding: 8px 12px;
        border: 1px solid var(--line);
        border-radius: 999px;
        background: rgba(255, 255, 255, 0.03);
        width: fit-content;
      }
      .dot {
        width: 9px;
        height: 9px;
        border-radius: 999px;
        background: var(--accent);
        box-shadow: 0 0 0 6px rgba(122, 162, 255, 0.15);
      }
      .badge span {
        color: var(--muted);
        font-size: 13px;
        font-weight: 500;
      }

      .nav {
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
      }
      .nav a {
        font-size: 13px;
        color: var(--muted);
        border: 1px solid var(--line);
        background: rgba(255, 255, 255, 0.02);
        padding: 7px 10px;
        border-radius: 999px;
      }
      .nav a:hover { color: var(--text); text-decoration: none; }

      h1 {
        margin: 0;
        font-size: clamp(28px, 4vw, 44px);
        letter-spacing: -0.02em;
        line-height: 1.15;
      }
      .subtitle {
        margin: 0;
        color: var(--muted);
        font-size: clamp(15px, 2vw, 18px);
        max-width: 95ch;
      }

      .meta {
        display: grid;
        gap: 8px;
        margin-top: 2px;
      }

      .authors {
        color: var(--text);
        font-weight: 600;
        flex-wrap: wrap;
        font-size: 14px;
      }
      .authors a {
        color: var(--text);
        text-decoration: none;
        border-bottom: 1px solid rgba(255,255,255,0.15);
      }
      .authors a:hover {
        text-decoration: none;
        border-bottom-color: rgba(255,255,255,0.45);
      }

      .affils {
        color: var(--muted);
        font-size: 14px;
      }

      .cta {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
        margin-top: 10px;
      }
      .btn {
        display: inline-flex;
        align-items: center;
        gap: 10px;
        padding: 10px 14px;
        border-radius: 12px;
        border: 1px solid var(--line);
        background: rgba(255, 255, 255, 0.03);
        box-shadow: var(--shadow);
        font-weight: 600;
        font-size: 14px;
        cursor: pointer;
        user-select: none;
      }
      .btn:hover { background: rgba(255, 255, 255, 0.06); text-decoration: none; }
      .btn.primary {
        border-color: rgba(122, 162, 255, 0.50);
        background: linear-gradient(180deg, rgba(122, 162, 255, 0.20), rgba(122, 162, 255, 0.06));
      }
      .btn.disabled {
        opacity: 0.55;
        cursor: not-allowed;
        box-shadow: none;
      }
      .btn .pill {
        padding: 3px 8px;
        border-radius: 999px;
        border: 1px solid var(--line);
        color: var(--muted);
        font-weight: 600;
        font-size: 12px;
      }

      .card {
        margin-top: 16px;
        background: rgba(255, 255, 255, 0.03);
        border: 1px solid var(--line);
        border-radius: 16px;
        box-shadow: var(--shadow);
        padding: 18px;
      }

      .card h2 {
        margin: 0 0 10px;
        font-size: 16px;
        letter-spacing: -0.01em;
      }

      .card h3 {
        margin: 18px 0 8px;
        font-size: 14px;
        letter-spacing: -0.01em;
        color: var(--text);
      }

      .card p {
        margin: 0;
        color: var(--muted);
        font-size: 14px;
      }

      .section { margin-top: 18px; }

      .figgrid {
        display: grid;
        gap: 14px;
        margin-top: 14px;
      }
      @media (min-width: 920px) {
        .figgrid.two { grid-template-columns: 1fr 1fr; }
      }

      figure.figure {
        margin: 0;
        padding: 12px;
        border: 1px solid var(--line);
        border-radius: 14px;
        background: rgba(255, 255, 255, 0.02);
      }
      figure.figure img {
        width: 100%;
        height: auto;
        display: block;
        border-radius: 12px;
        border: 1px solid var(--line);
        background: rgba(255, 255, 255, 0.02);
      }
      figure.figure figcaption {
        margin-top: 10px;
        color: var(--muted);
        font-size: 13px;
      }

      .imgfail {
        border: 1px solid var(--line);
        border-radius: 12px;
        background: rgba(255, 255, 255, 0.02);
        padding: 12px;
        color: var(--muted);
        font-size: 13px;
      }

      .tablewrap {
        margin-top: 10px;
        overflow: auto;
        border: 1px solid var(--line);
        border-radius: 12px;
        background: rgba(255, 255, 255, 0.02);
      }
      table {
        width: 100%;
        border-collapse: collapse;
        font-size: 13px;
        min-width: 780px;
      }
      th, td {
        padding: 10px 10px;
        border-bottom: 1px solid var(--line);
        text-align: left;
        vertical-align: middle;
        white-space: nowrap;
      }
      th {
        color: var(--text);
        font-weight: 700;
        background: rgba(255, 255, 255, 0.03);
      }
      td { color: var(--muted); }
      tr:last-child td { border-bottom: none; }

      .strong { color: var(--text); font-weight: 700; }
      .u { text-decoration: underline; text-decoration-thickness: 1px; text-underline-offset: 3px; }

      .bibtex {
        margin-top: 10px;
        background: #0a0b0f;
        border: 1px solid var(--line);
        border-radius: 12px;
        padding: 12px;
        overflow: auto;
        font-size: 12px;
        color: #dfe7ff;
      }

      .note {
        margin-top: 10px;
        padding: 10px 12px;
        border: 1px solid var(--line);
        border-radius: 12px;
        background: rgba(255, 255, 255, 0.02);
        color: var(--muted);
        font-size: 13px;
      }

      footer {
        margin-top: 22px;
        color: var(--muted);
        font-size: 12px;
        display: flex;
        justify-content: space-between;
        flex-wrap: wrap;
        gap: 10px;
        border-top: 1px solid var(--line);
        padding-top: 16px;
      }

      .smalllink { color: var(--muted); }
      .smalllink:hover { color: var(--text); }

      .sr-only {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: 0;
        overflow: hidden;
        clip: rect(0,0,0,0);
        white-space: nowrap;
        border: 0;
      }

      code {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
        font-size: 12px;
        color: #dfe7ff;
      }

    /* Rollout video layout */
    .videogrid {
        display: flex;
        flex-wrap: wrap;
        gap: 12px;
        margin-top: 14px;
    }

    /* 4 models in one row on wide screens */
    .videogrid.cols-4 .video-card {
        flex: 1 1 calc((100% - 36px) / 4);
        min-width: 220px;
    }

    /* 2 models in one row when you only show two */
    .videogrid.cols-2 .video-card {
        flex: 1 1 calc((100% - 12px) / 2);
        min-width: 260px;
    }

    @media (max-width: 980px) {
        .videogrid.cols-4 .video-card { flex: 1 1 calc((100% - 12px) / 2); }
    }
    @media (max-width: 560px) {
        .videogrid.cols-4 .video-card,
        .videogrid.cols-2 .video-card { flex: 1 1 100%; min-width: 0; }
    }

    .video-card {
        padding: 12px;
        border: 1px solid var(--line);
        border-radius: 14px;
        background: rgba(255, 255, 255, 0.02);
    }

    .video-head {
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 10px;
        margin-bottom: 10px;
    }

    .video-left {
        display: flex;
        align-items: center;
        gap: 8px;
        min-width: 0;
    }

    .video-title {
        margin: 0;
        font-size: 13px;
        font-weight: 700;
        color: var(--text);
        letter-spacing: -0.01em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
        max-width: 220px;
    }

    .video-tag {
        font-size: 12px;
        font-weight: 700;
        color: var(--muted);
        border: 1px solid var(--line);
        padding: 3px 8px;
        border-radius: 999px;
        white-space: nowrap;
    }

    .video-wrap {
        border: 1px solid var(--line);
        border-radius: 12px;
        overflow: hidden;
        background: rgba(255, 255, 255, 0.02);
    }
    .video-wrap video {
        width: 100%;
        height: auto;
        display: block;
    }

    .video-cap {
        margin-top: 10px;
        font-size: 13px;
        color: var(--muted);
    }

    /* Success / Fail badge */
    .sf {
        font-size: 12px;
        font-weight: 800;
        letter-spacing: -0.01em;
        padding: 3px 8px;
        border-radius: 999px;
        border: 1px solid var(--line);
        white-space: nowrap;
    }
    .sf.success {
        color: #9ef7c8;
        border-color: rgba(166, 255, 203, 0.35);
        background: rgba(166, 255, 203, 0.10);
    }
    .sf.fail {
        color: #ffb3b3;
        border-color: rgba(255, 122, 122, 0.35);
        background: rgba(255, 122, 122, 0.10);
    }

    .video-note {
        margin-top: 10px;
        padding: 10px 12px;
        border: 1px solid var(--line);
        border-radius: 12px;
        background: rgba(255, 255, 255, 0.02);
        color: var(--muted);
        font-size: 13px;
    }
    </style>

    <script>
      window.MathJax = {
        tex: { inlineMath: [["$", "$"], ["\\(", "\\)"]] },
        options: { skipHtmlTags: ["script","noscript","style","textarea","pre","code"] }
      };
    </script>
    <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </head>

  <body>
    <div class="wrap">
      <header>
        <div class="topbar">
          <div class="badge" aria-label="project status">
            <div class="dot" aria-hidden="true"></div>
            <span>ArXiv Preprint</span>
          </div>

          <nav class="nav" aria-label="page">
            <a href="#abstract">Abstract</a>
            <a href="#introduction">Introduction</a>
            <a href="#method">Method</a>
            <a href="#experiments">Experiments</a>
            <a href="#lam-vis">Visualization</a>
            <a href="#bibtex">BibTeX</a>
            <a href="#rollouts">Rollouts</a>
          </nav>
        </div>

        <h1>MVP-LAM</h1>
        <p class="subtitle">
          Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction
        </p>

        <div class="meta">
          <div class="authors">
            <a href="https://tiny-gander-c11.notion.site/Jung-Min-Lee-709b80feb6c84a7281e46f1070920e5e">Jung Min Lee</a> ·
            <a href="https://dohyeoklee.github.io/">Dohyeok Lee</a> ·
            <a href="https://jmsnu.github.io/#">Seokhun Ju</a> ·
            <a href="https://jmsnu.github.io/#">Taehyun Cho</a> ·
            <a href="https://jmsnu.github.io/#">Jin Woo Koo</a> ·
            <a href="https://scholar.google.com/citations?user=b-LJkLQAAAAJ&hl=en">Li Zhao</a> ·
            <a href="https://sangwoohong.github.io/">Sangwoo Hong</a> ·
            <a href="https://cml.snu.ac.kr/">Jungwoo Lee</a>
          </div>
          <div class="affils">
            Seoul National University · Konkuk University · Microsoft Research Asia · HodooAI Labs
          </div>
        </div>

        <div class="cta" role="group" aria-label="links">
          <a class="btn primary disabled" href="#" aria-disabled="true" tabindex="-1">
            <span>arXiv</span>
            <span class="pill">Coming soon</span>
          </a>
          <a class="btn disabled" href="#" aria-disabled="true" tabindex="-1">
            <span>Code</span>
            <span class="pill">Coming soon</span>
          </a>
          <button class="btn" id="copy-bib" type="button">
            <span>Copy BibTeX</span>
            <span class="pill">1 click</span>
          </button>
        </div>
      </header>

      <main class="card">
        <h2 id="abstract">Abstract</h2>
        <p>
          Learning <em>latent actions</em> from diverse human videos enables scaling robot learning beyond embodiment-specific robot datasets, and these latent actions have recently been used as pseudo-action labels for vision-language-action (VLA) model pretraining.
          To make VLA pretraining effective, latent actions should contain information about the underlying agent's actions despite the absence of ground-truth labels.
          We propose <strong>M</strong>ulti-<strong>V</strong>iew<strong>P</strong>oint <strong>L</strong>atent <strong>A</strong>ction <strong>M</strong>odel (<strong>MVP-LAM</strong>), which learns discrete latent actions that are highly informative about ground-truth actions from time-synchronized multi-view videos.
          MVP-LAM trains latent actions with a <em>cross-viewpoint reconstruction</em> objective, so that a latent action inferred from one view must explain the future in another view, reducing reliance on viewpoint-specific cues.
          On Bridge V2, MVP-LAM produces more action-centric latent actions, achieving higher mutual information with ground-truth actions and improved action prediction, including under out-of-distribution evaluation.
          Finally, pretraining VLAs with MVP-LAM latent actions improves downstream manipulation performance on the SIMPLER and LIBERO-Long benchmarks.
        </p>

        <div class="section">
          <h2 id="introduction">Introduction</h2>
          <p>
            Collecting real-world robot demonstrations remains a central bottleneck in training generalist manipulation policies.
            Robot learning is constrained by the cost of acquiring action-labeled trajectories, which typically requires human teleoperation.
            This makes large-scale data collection slow and expensive, and the resulting datasets often depend on a specific embodiment and sensor setup.
            Learning from video exploits abundant human manipulation videos to acquire transferable priors over manipulation-relevant dynamics.
            A fundamental challenge is that such videos do not provide low-level action labels, preventing standard supervised imitation learning.
          </p>

          <div class="section">
            <p>
              A key obstacle for action-centric latent actions is that visual transitions can be spuriously influenced by factors other than the agent's actions yet still correlate with frame-to-frame changes.
              We focus on viewpoint variation.
              Viewpoint changes introduce camera movements and perspective shifts, entangling visual transitions with the agent's action.
              As a result, latent actions learned from single-view reconstruction can overfit to viewpoint-dependent cues and become less predictive of the actions.
            </p>
          </div>

          <figure class="figure" id="fig-concept">
            <img data-asset="concept.png" alt="Concept figure" loading="lazy" />
            <figcaption>
              <strong>Why viewpoint variation interferes with learning latent actions.</strong>
              Viewpoint variation acts as noise.
              Frame-to-frame visual differences reflect both interaction-driven state changes and viewpoint-dependent appearance changes (e.g., camera movements).
              Because these factors are entangled, the same underlying action can induce different visual transitions across viewpoints.
              This confounding makes it difficult to learn latent actions that are consistently predictive of the underlying control actions.
            </figcaption>
          </figure>

          <div class="section">
            <p>
              We propose Multi-ViewPoint Latent Action Model, which learns discrete latent actions that are highly informative about ground-truth actions.
              MVP-LAM is trained on time-synchronized multi-view videos with a cross-viewpoint reconstruction objective, where a latent action inferred from one view is used to predict the future observation in another view.
              This discourages latent actions from encoding viewpoint-specific information and yields more action-centric latent actions.
            </p>
          </div>
        </div>

        <div class="section">
          <h2 id="method">Method</h2>

          <h3>Action-centric Latent Action</h3>
          <p>
            When latent actions are used as pseudo-action labels for behavior cloning policies, it is desirable that the learned latent action $Z_t$ preserves as much information as possible about the underlying action $A_t$.
            We denote the state by $S_t$, and assume an expert policy induces actions $A_t \sim \pi^\star(\cdot \mid S_t)$.
            In the pretraining stage, we typically do not observe $S_t$ or $A_t$.
            Instead, we only observe images or their features $O_t = f(I_t)$.
            LAM produces latent actions from consecutive observations, $Z_t = E_{\theta}(O_t, O_{t+1})$, with vector quantization when using VQ-VAE.
          </p>

          <div class="section">
            <p>
              We define a latent action $Z_t$ action-centric if it is highly informative about the underlying action $A_t$.
              We quantify this by mutual information and consider the objective
              $$\max_{Z_t}\ \mathcal{I}(Z_t; A_t).$$
              In this context, viewpoint variation acts as noise.
              Changes in camera pose $V_t$ can induce frame-to-frame differences in $O_t$ that are predictive of $Z_t$ but are not caused by the action $A_t$.
              When $Z_t$ is learned under a limited-capacity bottleneck such as vector quantization, allocating representational capacity to viewpoint-dependent factors can come at the expense of action-relevant dynamics and reduce $\mathcal{I}(Z_t;A_t)$.
            </p>
          </div>

          <h3>Multi-Viewpoint Latent Action Learning</h3>
          <p>
            MVP-LAM leverages time-synchronized multi-view videos and cross-viewpoint reconstruction to learn action-centric latent actions.
            For clarity, we describe the two-view case but the objective extends to more views.
          </p>

          <figure class="figure" id="fig-arch">
            <img data-asset="arch.png" alt="Architecture figure" loading="lazy" />
            <figcaption>
              <strong>MVP-LAM training with time-synchronized multi-view videos.</strong>
              (1) <em>Self-viewpoint reconstruction</em> (left): for each view $v$, frozen DINOv2 extracts features $(o_t^v,o_{t+1}^v)$.
              A spatiotemporal encoder produces a continuous latent $e_t^v$ that is vector-quantized into a discrete token $z_t^v$, and a decoder reconstructs $o_{t+1}^v$ from $(o_t^v,z_t^v)$.
              (2) <em>Cross-viewpoint reconstruction</em> (right): MVP-LAM swaps latent tokens across views (e.g., $z_t^{v_1}\leftrightarrow z_t^{v_2}$) while reconstructing each view’s future feature, encouraging $z_t$ to capture inherent transition information.
            </figcaption>
          </figure>
        </div>

        <div class="section">
          <h2 id="experiments">Experiments</h2>

          <h3><strong>RQ1.</strong> Are MVP-LAM latent actions more action-centric</h3>
          <p>
            We evaluate action-centricity by measuring mutual information between latent actions and ground-truth actions, and by predicting actions from latent actions with a linear probe.
          </p>

          <div class="figgrid two" aria-label="RQ1 figures">
            <figure class="figure" id="fig-mi">
              <img data-asset="mi.png" alt="Mutual information figure" loading="lazy" />
              <figcaption>
                <strong>Estimated mutual information.</strong>
                $\mathcal{I}(Z;A)$ on Bridge V2 with KSG, BA, and MINE estimators.
                For KSG, latent actions are randomly projected to $d{=}256$ prior to estimation.
                Higher is better.
                Error bars show standard deviation over four seeds.
              </figcaption>
            </figure>

            <figure class="figure" id="fig-probe">
              <img data-asset="linear_probe.png" alt="Linear probing figure" loading="lazy" />
              <figcaption>
                <strong>Linear probing result.</strong>
                NMSE of a linear layer predicting actions from latent actions.
                Bridge V2 is in-distribution.
                LIBERO Spatial Object Goal Long are out-of-distribution.
                Lower is better.
                Error bars show standard deviation over four seeds.
              </figcaption>
            </figure>
          </div>

          <h3><strong>RQ2.</strong> Is MVP-LAM Effective for Manipulation</h3>
          <p>
            Pretraining with MVP-LAM latent actions improves downstream manipulation.
            The average success rate increases from 39.6 percent to 60.4 percent on SIMPLER.
            On LIBERO-Long, MVP-LAM achieves 90.8 percent success, improving over UniVLA pretrained on Bridge V2 at 79.4 percent.
          </p>
        </div>

        <div class="section">
          <h2>SIMPLER benchmark result</h2>
          <p class="note">
            We report success rate and grasping rate (%) on the SIMPLER benchmark.
            † denotes results reported in prior work.
            Best is bolded and second best is underlined.
          </p>

          <div class="tablewrap">
            <table aria-label="SIMPLER benchmark result table">
              <thead>
                <tr>
                  <th>Success Rate</th>
                  <th>MVP-LAM</th>
                  <th>UniVLA</th>
                  <th>LAPA†</th>
                  <th>OpenVLA†</th>
                  <th>Octo-Small</th>
                  <th>Octo-Base</th>
                  <th>$\pi_{0}$</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td class="strong">StackG2Y</td>
                  <td>33.3</td>
                  <td>16.7</td>
                  <td class="strong">54.2</td>
                  <td class="u">41.6</td>
                  <td>8.3</td>
                  <td>0.0</td>
                  <td>37.5</td>
                </tr>
                <tr>
                  <td class="strong">Carrot2Plate</td>
                  <td class="strong">66.7</td>
                  <td>20.8</td>
                  <td>45.8</td>
                  <td class="u">50.0</td>
                  <td>33.3</td>
                  <td>37.5</td>
                  <td>33.3</td>
                </tr>
                <tr>
                  <td class="strong">Spoon2Towel</td>
                  <td class="u">66.7</td>
                  <td>54.2</td>
                  <td class="strong">70.8</td>
                  <td>37.5</td>
                  <td>25.0</td>
                  <td>12.5</td>
                  <td>29.2</td>
                </tr>
                <tr>
                  <td class="strong">Eggplant2Bask</td>
                  <td class="strong">75.0</td>
                  <td class="u">66.7</td>
                  <td>58.3</td>
                  <td>16.7</td>
                  <td>12.5</td>
                  <td>20.8</td>
                  <td>45.8</td>
                </tr>
                <tr>
                  <td class="strong">AVG</td>
                  <td class="strong">60.4</td>
                  <td>39.6</td>
                  <td class="u">57.3</td>
                  <td>36.4</td>
                  <td>19.8</td>
                  <td>17.7</td>
                  <td>36.5</td>
                </tr>

                <tr>
                  <th>Grasping Rate</th>
                  <th colspan="7"></th>
                </tr>

                <tr>
                  <td class="strong">StackG2Y</td>
                  <td>54.3</td>
                  <td>45.8</td>
                  <td class="u">62.5</td>
                  <td>50.0</td>
                  <td>54.2</td>
                  <td class="strong">70.8</td>
                  <td>58.3</td>
                </tr>
                <tr>
                  <td class="strong">Carrot2Plate</td>
                  <td class="u">70.8</td>
                  <td>37.5</td>
                  <td>58.3</td>
                  <td>66.6</td>
                  <td class="strong">75.0</td>
                  <td>54.2</td>
                  <td>58.3</td>
                </tr>
                <tr>
                  <td class="strong">Spoon2Towel</td>
                  <td class="u">79.2</td>
                  <td class="u">79.2</td>
                  <td class="strong">83.3</td>
                  <td>45.8</td>
                  <td>66.7</td>
                  <td>70.8</td>
                  <td>54.2</td>
                </tr>
                <tr>
                  <td class="strong">Eggplant2Bask</td>
                  <td class="u">95.8</td>
                  <td class="strong">100.0</td>
                  <td>83.3</td>
                  <td>37.5</td>
                  <td>50.0</td>
                  <td>54.2</td>
                  <td>87.5</td>
                </tr>
                <tr>
                  <td class="strong">AVG</td>
                  <td class="strong">75.0</td>
                  <td>65.6</td>
                  <td class="u">71.9</td>
                  <td>50.0</td>
                  <td>61.5</td>
                  <td>62.5</td>
                  <td>64.6</td>
                </tr>
              </tbody>
            </table>
          </div>

          <h2>LIBERO-Long results</h2>
          <p class="note">
            Success rate (%) on LIBERO-Long.
            † indicates results reported in prior work and * indicates methods that use additional wrist-view images and states.
            Best is bolded and second best is underlined.
          </p>

          <div class="tablewrap">
            <table aria-label="LIBERO-Long results table">
              <thead>
                <tr>
                  <th>MVP-LAM</th>
                  <th>UniVLA (Bridge)</th>
                  <th>OpenVLA †</th>
                  <th>$\pi_0$ † *</th>
                  <th>UniVLA † (OXE)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td class="strong">90.8</td>
                  <td class="u">79.4</td>
                  <td>53.7</td>
                  <td>85.2</td>
                  <td>92.0</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>

        <div class="section">
          <h2 id="lam-vis">Visualization of MVP-LAM</h2>
          <figure class="figure" id="fig-lam-vis">
            <img data-asset="latent_action_vis.png" alt="lam_vis" loading="lazy" />
            <figcaption>
              Qualitative latent action visualization. Example frame transitions and the corresponding MVP-LAM discrete codes selected for each transition.
            </figcaption>
          </figure>
        </div>

        <div class="section">
          <h2 id="bibtex">BibTeX</h2>
          <pre class="bibtex" id="bibtex-block" aria-label="bibtex">
@misc{lee2026mvplam,
  title  = {MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction},
  author = {Lee, Jung Min and Lee, Dohyeok and Ju, Seokhun and Cho, Taehyun and Koo, Jin Woo and Zhao, Li and Hong, Sangwoo and Lee, Jungwoo},
  year   = {2026},
  note   = {arXiv preprint, coming soon}
}
          </pre>
          <span class="sr-only" id="copy-status" aria-live="polite"></span>
        </div>
      </main>

    </div>
    <div class="wrap">
    <div class="section" id="rollouts">
    <h2>Rollout videos</h2>

    <p class="note">
        Place videos under <code>assets/videos/</code>.
        Use <code>.mp4</code> with H.264 for browser compatibility.
    </p>

    <div class="section">
        <h3>SIMPLER</h3>

        <!-- Task 1 -->
        <h3>StackG2Y</h3>
        <div class="videogrid cols-4">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left">
                <p class="video-title">StackG2Y</p>
                <span class="video-tag">mvp-lam</span>
            </div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap">
            <video controls preload="metadata" playsinline muted>
                <source src="assets/videos/simpler/stackg2y/mvp-lam.mp4" type="video/mp4" />
            </video>
            </div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left">
                <p class="video-title">StackG2Y</p>
                <span class="video-tag">univla</span>
            </div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap">
            <video controls preload="metadata" playsinline muted>
                <source src="assets/videos/simpler/stackg2y/univla.mp4" type="video/mp4" />
            </video>
            </div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left">
                <p class="video-title">StackG2Y</p>
                <span class="video-tag">octo</span>
            </div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap">
            <video controls preload="metadata" playsinline muted>
                <source src="assets/videos/simpler/stackg2y/octo.mp4" type="video/mp4" />
            </video>
            </div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left">
                <p class="video-title">StackG2Y</p>
                <span class="video-tag">pi0</span>
            </div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap">
            <video controls preload="metadata" playsinline muted>
                <source src="assets/videos/simpler/stackg2y/pi0.mp4" type="video/mp4" />
            </video>
            </div>
        </div>
        </div>

        <!-- Task 2 -->
        <h3>Carrot2Plate</h3>
        <div class="videogrid cols-4">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Carrot2Plate</p><span class="video-tag">mvp-lam</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/carrot2plate/mvp-lam.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Carrot2Plate</p><span class="video-tag">univla</span></div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/carrot2plate/univla.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Carrot2Plate</p><span class="video-tag">octo</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/carrot2plate/octo.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Carrot2Plate</p><span class="video-tag">pi0</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/carrot2plate/pi0.mp4" type="video/mp4" />
            </video></div>
        </div>
        </div>

        <!-- Task 3 -->
        <h3>Spoon2Towel</h3>
        <div class="videogrid cols-4">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Spoon2Towel</p><span class="video-tag">mvp-lam</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/spoon2towel/mvp-lam.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Spoon2Towel</p><span class="video-tag">univla</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/spoon2towel/univla.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Spoon2Towel</p><span class="video-tag">octo</span></div>
            <span class="sf success">Succes</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/spoon2towel/octo.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Spoon2Towel</p><span class="video-tag">pi0</span></div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/spoon2towel/pi0.mp4" type="video/mp4" />
            </video></div>
        </div>
        </div>

        <!-- Task 4 -->
        <h3>Eggplant2Bask</h3>
        <div class="videogrid cols-4">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Eggplant2Bask</p><span class="video-tag">mvp-lam</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/eggplant2bask/mvp-lam.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Eggplant2Bask</p><span class="video-tag">univla</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/eggplant2bask/univla.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Eggplant2Bask</p><span class="video-tag">octo</span></div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/eggplant2bask/octo.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">Eggplant2Bask</p><span class="video-tag">pi0</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/simpler/eggplant2bask/pi0.mp4" type="video/mp4" />
            </video></div>
        </div>
        </div>
    </div>

    <div class="section">
        <h3>LIBERO-Long</h3>
        <!-- LIBERO task 1 -->
        <h3>Put the white mug on the left plate and put the yellow and white mug on the right plate</h3>
        <div class="videogrid cols-2">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">LIBERO</p><span class="video-tag">mvp-lam</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/libero/mug_to_plates/mvp-lam.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">LIBERO</p><span class="video-tag">univla</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/libero/mug_to_plates/univla.mp4" type="video/mp4" />
            </video></div>
        </div>
        </div>

        <!-- LIBERO task 2 -->
        <h3>Put both moka pots on the stove</h3>
        <div class="videogrid cols-2">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">LIBERO</p><span class="video-tag">mvp-lam</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/libero/moka_to_stove/mvp-lam.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">LIBERO</p><span class="video-tag">univla</span></div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/libero/moka_to_stove/univla.mp4" type="video/mp4" />
            </video></div>
        </div>
        </div>

        <!-- LIBERO task 3 -->
        <h3>Put the yellow and white mug in the microwave and close it</h3>
        <div class="videogrid cols-2">
        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">LIBERO</p><span class="video-tag">mvp-lam</span></div>
            <span class="sf success">Success</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/libero/mug_to_microwave/mvp-lam.mp4" type="video/mp4" />
            </video></div>
        </div>

        <div class="video-card">
            <div class="video-head">
            <div class="video-left"><p class="video-title">LIBERO</p><span class="video-tag">univla</span></div>
            <span class="sf fail">Fail</span>
            </div>
            <div class="video-wrap"><video controls preload="metadata" playsinline muted>
            <source src="assets/videos/libero/mug_to_microwave/univla.mp4" type="video/mp4" />
            </video></div>
        </div>
        </div>
    </div>
    </div>
    </div>


    <script>
      (function () {
        var yearEl = document.getElementById("year");
        if (yearEl) yearEl.textContent = String(new Date().getFullYear());

        var copyBtn = document.getElementById("copy-bib");
        var bib = document.getElementById("bibtex-block");
        var status = document.getElementById("copy-status");

        function setStatus(msg) {
          if (!status) return;
          status.textContent = msg;
          setTimeout(function () { status.textContent = ""; }, 1200);
        }

        if (copyBtn && bib) {
          copyBtn.addEventListener("click", async function () {
            var text = bib.textContent.trim();
            try {
              await navigator.clipboard.writeText(text);
              setStatus("BibTeX copied");
            } catch (e) {
              var ta = document.createElement("textarea");
              ta.value = text;
              document.body.appendChild(ta);
              ta.select();
              document.execCommand("copy");
              document.body.removeChild(ta);
              setStatus("BibTeX copied");
            }
          });
        }

        function tryLoad(img, paths, idx) {
          if (idx >= paths.length) {
            var box = document.createElement("div");
            box.className = "imgfail";
            box.textContent = "Image missing. Expected one of these paths: " + paths.join(" , ");
            img.replaceWith(box);
            return;
          }
          img.src = paths[idx];
          img.onerror = function () { tryLoad(img, paths, idx + 1); };
        }

        var imgs = document.querySelectorAll("img[data-asset]");
        imgs.forEach(function (img) {
          var name = img.getAttribute("data-asset");
          var paths = [
            "assets/" + name,
            "asset/" + name,
            "./assets/" + name,
            "./asset/" + name
          ];
          tryLoad(img, paths, 0);
        });
      })();
    </script>
  </body>
</html>
